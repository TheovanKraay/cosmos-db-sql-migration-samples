{"cells":[{"cell_type":"code","source":["import uuid\nimport pyspark.sql.functions as F\nfrom pyspark.sql.functions import col\nfrom pyspark.sql.types import StringType,DateType,LongType,IntegerType,TimestampType\n\n#JDBC connect details for SQL Server database\njdbcHostname = \"jdbcHostname\"\njdbcDatabase = \"jdbcDatabase\"\njdbcUsername = \"jdbcUsername\"\njdbcPassword = \"jdbcPassword\"\njdbcPort = \"1433\"\n\nconnectionProperties = {\n  \"user\" : jdbcUsername,\n  \"password\" : jdbcPassword,\n  \"driver\" : \"com.microsoft.sqlserver.jdbc.SQLServerDriver\"\n}\n\njdbcUrl = \"jdbc:sqlserver://{0}:{1};database={2};user={3};password={4}\".format(jdbcHostname, jdbcPort, jdbcDatabase, jdbcUsername, jdbcPassword)\nwriteConfig = {\n    \"Endpoint\": \"Endpoint\",\n    \"Masterkey\": \"Masterkey\",\n    \"Database\": \"Movies\",\n    \"Collection\": \"Orders\",\n    \"Upsert\": \"true\"\n}"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["import json\nimport ast\nimport pyspark.sql.functions as F\nfrom azure.cosmos import exceptions, CosmosClient, PartitionKey\nfrom pyspark.sql import SQLContext\nfrom pyspark.sql.types import *\nfrom pyspark.sql import *\nfrom pyspark.sql.functions import exp\nfrom pyspark.sql.functions import col\nfrom pyspark.sql.functions import lit\nfrom pyspark.sql.functions import array\nfrom pyspark.sql.types import *\n\n#get all orders\norders = sqlContext.read.jdbc(url=jdbcUrl, table=\"orders\", properties=connectionProperties)\n\n#get all order details\norderdetails = sqlContext.read.jdbc(url=jdbcUrl, table=\"orderdetails\", properties=connectionProperties)\n\n#filter on OrderId to loop\ncols = orders.select('OrderId').collect()\n\ncounter = 1\nfor col in cols:\n  #filter the order on current loop\n  order = orders.filter(orders['OrderId'] == col[0])\n  \n  #set id to be iterator number\n  order = order.withColumn(\"id\", lit(str(counter)))\n  \n  #add details field to order dataframe\n  order = order.withColumn(\"details\", lit(0))\n  \n  #filter order details dataframe to get details we want to merge into the order document\n  orderdetailsgroup = orderdetails.filter(orderdetails['OrderId'] == col[0])\n  \n  #convert dataframe to pandas because of trouble putting array type into spark dataframe field\n  orderpandas = order.toPandas()\n  \n  #convert details dataframe to json, but only if details were returned\n  if (orderdetailsgroup.count() !=0):\n    jsonstring = orderdetailsgroup.toJSON().collect()\n    \n    #set details field to be the details json array\n    orderpandas['details'][0] = jsonstring    \n  \n  #convert the order dataframe to json do some string manipulation to get valid json\n  orderjson = orderpandas.to_json(orient='records')\n  results = orderjson\n  results = results.replace(\"\\\\\", \"\")\n  results = results.replace(\"[\\\"\", \"[\")\n  results = results.replace(\"\\\"]\", \"]\")\n  results = results.replace(\"}\\\",\\\"{\", \"},{\")\n  results = results.replace(\"\\\"\", \"'\")\n  results = results[1:-1] \n  \n  #read json into spark dataframe\n  df = spark.read.json(sc.parallelize([results]))\n  \n  #write the dataframe (single order record with merged many-to-one order details) to cosmos db using spark connector\n  df.write.format(\"com.microsoft.azure.cosmosdb.spark\").mode(\"append\").options(**writeConfig).save()\n  \n  #increment the counter\n  counter += 1"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/local_disk0/tmp/1575531358606-0/PythonShell.py:45: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame\n\nSee the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n  from IPython.utils.strdispatch import StrDispatch\n</div>"]}}],"execution_count":2},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":3}],"metadata":{"name":"sql-to-cosmos","notebookId":1441396999859995},"nbformat":4,"nbformat_minor":0}
